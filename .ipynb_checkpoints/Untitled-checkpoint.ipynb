{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/orangutan/keras-vgg19-starter\n",
    "df_train = pd.read_csv('Data/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n02098413_2584</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n02098413_6354</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>n02098413_12117</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>n02098413_10144</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>n02098413_13405</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>n02098413_1718</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>n02098413_3798</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>n02098413_4592</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>n02098413_13638</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>n02098413_8575</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>n02098413_631</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>n02098413_5382</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>n02098413_20614</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>n02098413_5594</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>n02098413_2199</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>n02098413_1713</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>n02098413_16009</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>n02098413_387</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>n02098413_49</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>n02098413_3995</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>n02098413_6923</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>n02098413_18706</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>n02098413_16322</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>n02098413_1719</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>n02098413_7441</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>n02098413_10966</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>n02098413_5476</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>n02098413_1522</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>n02098413_8214</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>n02098413_244</td>\n",
       "      <td>lhasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20550</th>\n",
       "      <td>20550</td>\n",
       "      <td>n02101556_7317</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551</th>\n",
       "      <td>20551</td>\n",
       "      <td>n02101556_6037</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20552</th>\n",
       "      <td>20552</td>\n",
       "      <td>n02101556_2023</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20553</th>\n",
       "      <td>20553</td>\n",
       "      <td>n02101556_1018</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20554</th>\n",
       "      <td>20554</td>\n",
       "      <td>n02101556_5252</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555</th>\n",
       "      <td>20555</td>\n",
       "      <td>n02101556_129</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>20556</td>\n",
       "      <td>n02101556_5449</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20557</th>\n",
       "      <td>20557</td>\n",
       "      <td>n02101556_5023</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20558</th>\n",
       "      <td>20558</td>\n",
       "      <td>n02101556_5291</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>20559</td>\n",
       "      <td>n02101556_488</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20560</th>\n",
       "      <td>20560</td>\n",
       "      <td>n02101556_4028</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20561</th>\n",
       "      <td>20561</td>\n",
       "      <td>n02101556_4965</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20562</th>\n",
       "      <td>20562</td>\n",
       "      <td>n02101556_7987</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20563</th>\n",
       "      <td>20563</td>\n",
       "      <td>n02101556_8352</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>20564</td>\n",
       "      <td>n02101556_7923</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565</th>\n",
       "      <td>20565</td>\n",
       "      <td>n02101556_7927</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20566</th>\n",
       "      <td>20566</td>\n",
       "      <td>n02101556_1116</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20567</th>\n",
       "      <td>20567</td>\n",
       "      <td>n02101556_5137</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20568</th>\n",
       "      <td>20568</td>\n",
       "      <td>n02101556_2566</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20569</th>\n",
       "      <td>20569</td>\n",
       "      <td>n02101556_8148</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20570</th>\n",
       "      <td>20570</td>\n",
       "      <td>n02101556_3736</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20571</th>\n",
       "      <td>20571</td>\n",
       "      <td>n02101556_6983</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20572</th>\n",
       "      <td>20572</td>\n",
       "      <td>n02101556_3570</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20573</th>\n",
       "      <td>20573</td>\n",
       "      <td>n02101556_3660</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20574</th>\n",
       "      <td>20574</td>\n",
       "      <td>n02101556_7521</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>20575</td>\n",
       "      <td>n02101556_4241</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>20576</td>\n",
       "      <td>n02101556_5771</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20577</th>\n",
       "      <td>20577</td>\n",
       "      <td>n02101556_4226</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20578</th>\n",
       "      <td>20578</td>\n",
       "      <td>n02101556_5903</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>20579</td>\n",
       "      <td>n02101556_5512</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20580 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0               id    breed\n",
       "0               0   n02098413_2584    lhasa\n",
       "1               1   n02098413_6354    lhasa\n",
       "2               2  n02098413_12117    lhasa\n",
       "3               3  n02098413_10144    lhasa\n",
       "4               4  n02098413_13405    lhasa\n",
       "5               5   n02098413_1718    lhasa\n",
       "6               6   n02098413_3798    lhasa\n",
       "7               7   n02098413_4592    lhasa\n",
       "8               8  n02098413_13638    lhasa\n",
       "9               9   n02098413_8575    lhasa\n",
       "10             10    n02098413_631    lhasa\n",
       "11             11   n02098413_5382    lhasa\n",
       "12             12  n02098413_20614    lhasa\n",
       "13             13   n02098413_5594    lhasa\n",
       "14             14   n02098413_2199    lhasa\n",
       "15             15   n02098413_1713    lhasa\n",
       "16             16  n02098413_16009    lhasa\n",
       "17             17    n02098413_387    lhasa\n",
       "18             18     n02098413_49    lhasa\n",
       "19             19   n02098413_3995    lhasa\n",
       "20             20   n02098413_6923    lhasa\n",
       "21             21  n02098413_18706    lhasa\n",
       "22             22  n02098413_16322    lhasa\n",
       "23             23   n02098413_1719    lhasa\n",
       "24             24   n02098413_7441    lhasa\n",
       "25             25  n02098413_10966    lhasa\n",
       "26             26   n02098413_5476    lhasa\n",
       "27             27   n02098413_1522    lhasa\n",
       "28             28   n02098413_8214    lhasa\n",
       "29             29    n02098413_244    lhasa\n",
       "...           ...              ...      ...\n",
       "20550       20550   n02101556_7317  clumber\n",
       "20551       20551   n02101556_6037  clumber\n",
       "20552       20552   n02101556_2023  clumber\n",
       "20553       20553   n02101556_1018  clumber\n",
       "20554       20554   n02101556_5252  clumber\n",
       "20555       20555    n02101556_129  clumber\n",
       "20556       20556   n02101556_5449  clumber\n",
       "20557       20557   n02101556_5023  clumber\n",
       "20558       20558   n02101556_5291  clumber\n",
       "20559       20559    n02101556_488  clumber\n",
       "20560       20560   n02101556_4028  clumber\n",
       "20561       20561   n02101556_4965  clumber\n",
       "20562       20562   n02101556_7987  clumber\n",
       "20563       20563   n02101556_8352  clumber\n",
       "20564       20564   n02101556_7923  clumber\n",
       "20565       20565   n02101556_7927  clumber\n",
       "20566       20566   n02101556_1116  clumber\n",
       "20567       20567   n02101556_5137  clumber\n",
       "20568       20568   n02101556_2566  clumber\n",
       "20569       20569   n02101556_8148  clumber\n",
       "20570       20570   n02101556_3736  clumber\n",
       "20571       20571   n02101556_6983  clumber\n",
       "20572       20572   n02101556_3570  clumber\n",
       "20573       20573   n02101556_3660  clumber\n",
       "20574       20574   n02101556_7521  clumber\n",
       "20575       20575   n02101556_4241  clumber\n",
       "20576       20576   n02101556_5771  clumber\n",
       "20577       20577   n02101556_4226  clumber\n",
       "20578       20578   n02101556_5903  clumber\n",
       "20579       20579   n02101556_5512  clumber\n",
       "\n",
       "[20580 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_series = pd.Series(df_train['breed'])\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "\n",
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:33<00:00, 307.86it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "for f, breed in tqdm(df_train.values):\n",
    "    img = cv2.imread('Data/train/{}.jpg'.format(f))\n",
    "    label = one_hot_labels[i]\n",
    "    x_train.append(cv2.resize(img, (img_size, img_size)))\n",
    "    y_train.append(label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = np.array(y_train, np.uint8)\n",
    "x_train_raw = np.array(x_train, np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 224, 224, 3)\n",
      "(10222, 120)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = y_train_raw.shape[1]\n",
    "num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 10% of data as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train_raw, y_train_raw, test_size=0.1, random_state=1, stratify=y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seth/miniconda3/envs/DL/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "# Create the base pre-trained model\n",
    "# Can't download weights in the kernel\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Add a new top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=1e-5, nesterov=True), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1114319de73a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_valid_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'**** Split {} ****'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3, shuffle=True)\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(x_train_raw):\n",
    "    X_train_split, y_train_split = X_train[train_index], y_train[train_index]\n",
    "    X_valid_split, y_valid_split = X_train[test_index], y_train[test_index]\n",
    "    print('**** Split {} ****'.format(i))\n",
    "    i += 1\n",
    "    model.fit(X_train_split, y_train_split, epochs=30, validation_data=(X_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9199/9199 [==============================] - 49s 5ms/step - loss: 2.6196 - acc: 0.4050\n",
      "Epoch 2/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.1045 - acc: 0.9790\n",
      "Epoch 3/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0208 - acc: 0.9985\n",
      "Epoch 4/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0155 - acc: 0.9989\n",
      "Epoch 5/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0128 - acc: 0.9989\n",
      "Epoch 6/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0117 - acc: 0.9990\n",
      "Epoch 7/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0124 - acc: 0.9988\n",
      "Epoch 8/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0130 - acc: 0.9988\n",
      "Epoch 9/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0109 - acc: 0.9988\n",
      "Epoch 10/10\n",
      "9199/9199 [==============================] - 38s 4ms/step - loss: 0.0097 - acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3b55e32b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 6s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.520991241477452, 0.01075268814291073]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
